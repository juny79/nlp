/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /opt/conda/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

====================================================================================================
📊 v4 품질 저하 원인 종합 분석
====================================================================================================

📂 데이터 로드 완료

====================================================================================================
1. ROUGE 점수 비교 분석
====================================================================================================

⏳ ROUGE 평가 중...

  평가 중: v3_original          ✅
  평가 중: v3_microtuned        ✅
  평가 중: v4_original          ✅

====================================================================================================
ROUGE 점수 상세 비교
====================================================================================================

Version                 ROUGE-1    ROUGE-2    ROUGE-L   Combined         리더보드
----------------------------------------------------------------------------------------------------
v3_original              46.73%     22.11%     41.68%   36.8377      51.8026
v3_microtuned            46.90%     22.28%     41.83%   37.0025    51.9421 ✅
v4_original              44.59%     19.19%     39.93%   34.5715   51.7703 ⚠️

====================================================================================================
차이 분석 (v4 vs v3_microtuned)
====================================================================================================

  ROUGE-1 차이: -2.30%p  (-4.91% 변화)
  ROUGE-2 차이: -3.08%p  (-13.84% 변화) ⚠️
  ROUGE-L 차이: -1.91%p  (-4.56% 변화)
  Combined 차이: -2.4311  (-6.57% 변화)

💡 핵심 문제:
  → ROUGE-2가 3.08%p 낮음 (바이그램 매칭 저하)
  → 이는 중요 구문의 정확도가 떨어짐을 의미

====================================================================================================
2. 텍스트 길이 및 구조 분석
====================================================================================================

📏 길이 통계:

  Version                    평균      중앙값     표준편차       최소       최대
  --------------------------------------------------------------------------------
  Dev (정답)                 15.3       14      6.7        5       54
  v3_microtuned            15.6       14      6.0        6       32
  v4_original              16.9       16      6.9        5       38

📊 분석:
  v4가 v3보다 평균 +1.2 단어 더 김
  Dev 정답과의 차이: v3는 +0.3, v4는 +1.5
  → v4는 불필요한 정보를 더 많이 포함

📝 문장 수 통계:

  v3_microtuned: 평균 2.7개 문장
  v4_original:   평균 2.8개 문장
  → v4가 평균 +0.1개 문장 더 많음

====================================================================================================
3. 어휘 다양성 및 반복 패턴 분석
====================================================================================================

📚 어휘 다양성 (높을수록 좋음):
  v3_microtuned: 0.4720
  v4_original:   0.4852
  차이: +0.0132 (+2.79%)

🔁 반복 패턴 (낮을수록 좋음):
  v3_microtuned: 44개 반복 바이그램
  v4_original:   52개 반복 바이그램
  차이: +8개
💡 분석: v4는 불필요한 반복이 많음 → ROUGE-2 저하 원인

====================================================================================================
4. 정보 밀도 분석 (ROUGE per word)
====================================================================================================

📈 ROUGE-2 per word (정보 밀도):
  v3_microtuned: 1.4243 (ROUGE-2 22.28% / 15.6 단어)
  v4_original:   1.1370 (ROUGE-2 19.19% / 16.9 단어)
  차이: -0.2874 (-20.18%)

💡 핵심 발견:
  → v4는 단어당 정보 밀도가 20.2% 낮음
  → 같은 내용을 표현하는데 더 많은 단어 사용 (비효율적)
  → 불필요한 수식어, 반복, 세부사항이 많음

====================================================================================================
5. 구체적 샘플 품질 비교 (Dev 정답 기준)
====================================================================================================

🔍 품질 차이가 큰 상위 5개 샘플:

[1] 샘플 96 (v3가 100.0%p 더 높음)
  Dev 정답 (14 단어): #Person2#는 수요일에 매니저와의 인터뷰 일정이 잡혀 있으며, #Person1#과 만나 커피를 마시며 이야기를 나눌 예정이다....
  v3 (6 단어, ROUGE-2: 100.0%): #Person2#는 #Person1#에게 룸메이트와 헤어져서 이사했다고 말합니다....
  v4 (6 단어, ROUGE-2: 0.0%): 빌은 #Person1#에게 룸메이트와 헤어져서 이사했다고 말합니다....
  💡 v3가 더 나은 이유: v4가 너무 짧음

[2] 샘플 226 (v3가 100.0%p 더 높음)
  Dev 정답 (18 단어): #Person2#는 도자기가 들어 있는 소포를 항공우편으로 장춘에 보내려 합니다. #Person1#은 깨지기 쉬운 물품이므로 튼튼한 박스에 포장...
  v3 (6 단어, ROUGE-2: 100.0%): #Person2#는 #Person1#에게 팁을 받지 않는다고 설명합니다....
  v4 (12 단어, ROUGE-2: 0.0%): #Person1#은 #Person2#에게 식사비를 지불하며 팁을 주려 했으나, #Person2#는 팁을 받지 않는다고 설명합니다....
  💡 v3가 더 나은 이유: v4가 너무 김 (+6단어)

[3] 샘플 463 (v3가 100.0%p 더 높음)
  Dev 정답 (9 단어): #Person1#과 #Person2#는 서로의 바쁜 일상과 여행 계획에 대해 이야기합니다....
  v3 (8 단어, ROUGE-2: 100.0%): #Person1#은 #Person2#의 도움을 받아 티켓을 예약하고 카드로 결제합니다....
  v4 (10 단어, ROUGE-2: 0.0%): #Person2#는 #Person1#의 티켓 예약을 도와주고, #Person1#은 카드로 티켓 비용을 결제합니다....
  💡 v3가 더 나은 이유: v4의 표현이 부정확함

[4] 샘플 469 (v3가 100.0%p 더 높음)
  Dev 정답 (12 단어): #Person1#은 #Person2#에게 생일과 영화 시작 시간을 묻고, 영화 시간에 맞추기 어려움을 토로합니다....
  v3 (9 단어, ROUGE-2: 100.0%): #Person1#은 #Person2#에게 영어 교육과 다른 언어 능력에 대해 질문합니다....
  v4 (9 단어, ROUGE-2: 0.0%): #Person2#는 영어 말하기와 쓰기에 능숙하며, 중학교부터 영어를 공부하기 시작했습니다....
  💡 v3가 더 나은 이유: v4의 표현이 부정확함

[5] 샘플 310 (v3가 75.0%p 더 높음)
  Dev 정답 (33 단어): #Person1#은 #Person2#에게 베토벤의 음악이 사람들을 더 똑똑하게 만든다는 이야기를 하지만, #Person2#는 그것이 사람들에게 ...
  v3 (19 단어, ROUGE-2: 75.0%): #Person1#은 #Person2#에게 이번 학기에 학교에서 새로운 과목들이 추가되어 숙제가 많아졌다고 말합니다. #Person1#은 과학을 ...
  v4 (14 단어, ROUGE-2: 0.0%): 다니엘은 과학을 가장 좋아하는 과목으로 꼽습니다. #Person2#는 다니엘이 장난꾸러기라고 생각하지만, 다니엘은 자신이 영리하다고 주장합니다....
  💡 v3가 더 나은 이유: v4가 너무 짧음


====================================================================================================
6. v1 vs v2 모델 성능 차이 추정
====================================================================================================

📊 모델별 초기 성능 (후처리 전):
  v1 모델 (v3_original):
    - ROUGE-2: 22.11%
    - 리더보드: 51.8026점
  v2 모델 (v4_original):
    - ROUGE-2: 19.19%
    - 리더보드: 51.7703점

🔻 성능 저하:
  ROUGE-2: -2.92%p
  리더보드: -0.0323점

💡 추정 원인:
  1. 과적합 (Overfitting): v2 학습 시 검증 데이터에 과적합
  2. 하이퍼파라미터: 학습률, 에폭 수 등이 부적절
  3. 프롬프트 불일치: inference 시 프롬프트가 학습과 다름
  4. 데이터 품질: v2 학습 데이터에 노이즈 포함

====================================================================================================
7. 종합 분석 및 결론
====================================================================================================

📋 v4 품질 저하 요인 종합:

  요인                        v3           v4           차이      심각도
  ----------------------------------------------------------------------
  ROUGE-2 점수            22.28%       19.19%      -3.08%p       높음
  → 바이그램 매칭 저하 → 핵심 구문 부정확
  정보 밀도                 1.4243       1.1370       -20.2%       높음
  → 단어당 정보량 감소 → 비효율적 표현
  평균 길이                 15.6단어       16.9단어         +1.2       중간
  → 불필요한 정보 포함 → 핵심 흐림
  어휘 다양성                0.4720       0.4852        +2.8%       낮음
  → 표현 단조로움
  반복 패턴                    44개          52개           +8       중간
  → 불필요한 반복 → ROUGE 저하

====================================================================================================
🎯 최종 결론
====================================================================================================

v4가 v3보다 품질이 낮은 이유:

  1️⃣ ROUGE-2 점수 3.08%p 낮음 (심각)
     → 핵심 구문(바이그램) 매칭이 13.8% 감소
     → 중요한 정보를 정확하게 표현하지 못함

  2️⃣ 정보 밀도 20.2% 낮음 (심각)
     → 같은 내용을 표현하는데 더 많은 단어 필요
     → 불필요한 수식어, 세부사항 과다 포함

  3️⃣ 평균 1.2단어 더 김 (중간)
     → Dev 정답(15.3단어)보다 1.5단어 더 김
     → 핵심이 흐려짐

  4️⃣ v2 모델 자체의 성능 저하 (근본 원인)
     → v1(51.8026) → v2(51.7703) = -0.0323점
     → 후처리로 해결 불가능

💡 개선 가능성:
  ❌ 후처리: 근본적 품질 문제로 효과 미미 (+0.04 최대)
  ❌ 미세조정: 오히려 악화 (-0.32 최악)
  ✅ 모델 교체: v1 사용 (v3_microtuned) → 51.9421점 보장

====================================================================================================

📄 상세 보고서를 저장합니다...
