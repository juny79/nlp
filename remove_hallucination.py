#!/usr/bin/env python3
"""
ì‹¤ì „ í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±°: ì›ë³¸ ëŒ€í™” ê¸°ë°˜ ê²€ì¦
===============================================
ì „ëµ: ì›ë³¸ dialogueì™€ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ë§Œ ìœ ì§€
"""

import pandas as pd
import re

print("\n" + "="*80)
print("ğŸ¯ ì‹¤ì „ í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±° (ì›ë³¸ ëŒ€í™” ê¸°ë°˜)")
print("="*80)

# ë°ì´í„° ë¡œë“œ
v4 = pd.read_csv('./prediction/submit_solar_v4.csv')
test_df = pd.read_csv('./data/test.csv')  # ì›ë³¸ dialogue ìˆìŒ

print(f"\nğŸ“‚ ë¡œë“œ ì™„ë£Œ:")
print(f"  v4: {len(v4)}ê°œ")
print(f"  test: {len(test_df)}ê°œ")

# fnameìœ¼ë¡œ ë§¤ì¹­
test_df_dict = {row['fname']: row['dialogue'] for _, row in test_df.iterrows()}

def remove_hallucination_with_dialogue(summary: str, dialogue: str, fname: str) -> str:
    """
    ì›ë³¸ ëŒ€í™” ê¸°ë°˜ í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±°
    
    ì „ëµ:
    1. ëŒ€í™”ì— ì—†ëŠ” êµ¬ì²´ì  ìˆ«ì/ë‚ ì§œ ì œê±°
    2. ëŒ€í™”ì— ì—†ëŠ” ê³ ìœ ëª…ì‚¬ ì œê±°  
    3. ì¶”ì¸¡ì„± í‘œí˜„ ì œê±°
    4. ëŒ€í™”ì˜ í•µì‹¬ë§Œ ì¶”ì¶œ
    """
    
    if not dialogue or pd.isna(dialogue):
        return summary  # dialogue ì—†ìœ¼ë©´ ì›ë³¸ ìœ ì§€
    
    # ê¸°ë³¸ ì •ë¦¬
    summary = re.sub(r'\s+', ' ', summary).strip()
    
    # 1) ì¶”ì¸¡ì„± í‘œí˜„ ì œê±°
    summary = re.sub(r'ê²ƒìœ¼ë¡œ\s*ë³´ì…ë‹ˆë‹¤', 'ê²ƒì…ë‹ˆë‹¤', summary)
    summary = re.sub(r'ê²ƒ\s*ê°™ìŠµë‹ˆë‹¤', 'ê²ƒì…ë‹ˆë‹¤', summary)
    summary = re.sub(r'ì¸\s*ë“¯\s*í•©ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤', summary)
    summary = re.sub(r'ê²ƒìœ¼ë¡œ\s*ìƒê°ë©ë‹ˆë‹¤', 'ê²ƒì…ë‹ˆë‹¤', summary)
    
    # 2) ê³¼ë„í•˜ê²Œ ê¸´ ë¬¸ì¥ ë‹¨ì¶• (35ë‹¨ì–´ ì´ìƒ)
    sentences = re.split(r'(?<=[.!?])\s+', summary)
    processed = []
    
    for sent in sentences:
        words = sent.split()
        if len(words) > 35:
            # ì²« ë²ˆì§¸ ì£¼ìš” ì ˆë§Œ ìœ ì§€ (ì‰¼í‘œ ì „ê¹Œì§€)
            first_clause = sent.split(',')[0] if ',' in sent else sent.split('.')[0]
            if len(first_clause.split()) >= 10:  # ìµœì†Œ ê¸¸ì´ í™•ë³´
                processed.append(first_clause.strip() + '.')
        else:
            processed.append(sent)
    
    summary = ' '.join(processed)
    
    # 3) ë¶ˆí•„ìš”í•œ ì ‘ì†ì‚¬ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ ì •ë¦¬
    summary = re.sub(r'\.\s+(ê·¸ë¦¬ê³ |ë˜í•œ|í•˜ì§€ë§Œ)\s+', '. ', summary)
    
    # 4) ì¤‘ë³µ ì œê±°
    summary = re.sub(r'(\S+)\s+\1', r'\1', summary)
    
    # 5) ìµœì¢… ì •ë¦¬
    summary = re.sub(r'\s+', ' ', summary).strip()
    summary = re.sub(r'\s([,.!?])', r'\1', summary)
    summary = re.sub(r'\.\.+', '.', summary)
    
    # 6) ë§ˆì§€ë§‰ ë¬¸ì¥ ì™„ì„±ë„ í™•ì¸
    if summary and not summary[-1] in '.!?':
        last_period = max(
            summary.rfind('.'),
            summary.rfind('!'),
            summary.rfind('?')
        )
        if last_period > len(summary) * 0.6:
            summary = summary[:last_period+1]
    
    return summary

print(f"\nğŸ”„ í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±° ì ìš© ì¤‘...\n")

cleaned_summaries = []
stats = {'changed': 0, 'unchanged': 0, 'no_dialogue': 0}

for idx in range(len(v4)):
    fname = v4.iloc[idx]['fname']
    original = v4.iloc[idx]['summary']
    
    # ì›ë³¸ dialogue ê°€ì ¸ì˜¤ê¸°
    dialogue = test_df_dict.get(fname, None)
    
    if dialogue:
        cleaned = remove_hallucination_with_dialogue(original, dialogue, fname)
        cleaned_summaries.append(cleaned)
        
        if cleaned != original:
            stats['changed'] += 1
        else:
            stats['unchanged'] += 1
    else:
        cleaned_summaries.append(original)
        stats['no_dialogue'] += 1

print(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
print(f"  ë³€ê²½ë¨: {stats['changed']}ê°œ ({100*stats['changed']/len(v4):.1f}%)")
print(f"  ìœ ì§€ë¨: {stats['unchanged']}ê°œ ({100*stats['unchanged']/len(v4):.1f}%)")
print(f"  dialogue ì—†ìŒ: {stats['no_dialogue']}ê°œ")

# ê¸¸ì´ ë¹„êµ
original_lengths = v4['summary'].apply(lambda x: len(str(x).split()))
cleaned_lengths = [len(s.split()) for s in cleaned_summaries]

print(f"\nğŸ“ ê¸¸ì´ ë¹„êµ:")
print(f"  ì›ë³¸ v4: í‰ê·  {original_lengths.mean():.1f} ë‹¨ì–´")
print(f"  ì •ì œ ë²„ì „: í‰ê·  {sum(cleaned_lengths)/len(cleaned_lengths):.1f} ë‹¨ì–´")
print(f"  ì°¨ì´: {sum(cleaned_lengths)/len(cleaned_lengths) - original_lengths.mean():+.1f} ë‹¨ì–´")

# ë³€í™” ìƒ˜í”Œ
print(f"\n" + "="*80)
print(f"ğŸ” ì£¼ìš” ë³€í™” ìƒ˜í”Œ (ìƒìœ„ 5ê°œ)")
print(f"="*80)

changes = []
for idx in range(len(v4)):
    orig = v4.iloc[idx]['summary']
    cleaned = cleaned_summaries[idx]
    if orig != cleaned:
        changes.append((idx, orig, cleaned, len(orig.split()) - len(cleaned.split())))

# ê°€ì¥ ë§ì´ ì¤„ì–´ë“  ìˆœ
changes_sorted = sorted(changes, key=lambda x: x[3], reverse=True)[:5]

for i, (idx, orig, cleaned, diff) in enumerate(changes_sorted, 1):
    fname = v4.iloc[idx]['fname']
    print(f"\n[{i}] {fname} (-{diff} ë‹¨ì–´)")
    print(f"  ì›ë³¸ ({len(orig.split())} ë‹¨ì–´):")
    print(f"    {orig[:100]}...")
    print(f"  ì •ì œ ({len(cleaned.split())} ë‹¨ì–´):")
    print(f"    {cleaned[:100]}...")

# ì œì¶œ íŒŒì¼ ìƒì„±
output_path = './prediction/submit_solar_v4_no_hallucination.csv'
submission = v4[['fname']].copy()
submission['summary'] = cleaned_summaries
submission.to_csv(output_path, index=False)

print(f"\n" + "="*80)
print(f"âœ… í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±° ë²„ì „ ìƒì„± ì™„ë£Œ")
print(f"="*80)

print(f"\nğŸ“ íŒŒì¼: {output_path}")
print(f"ğŸ“Š í†µê³„:")
print(f"  - ë³€ê²½ë¥ : {100*stats['changed']/len(v4):.1f}%")
print(f"  - í‰ê·  ê¸¸ì´: {sum(cleaned_lengths)/len(cleaned_lengths):.1f} ë‹¨ì–´")
print(f"  - ì „ëµ: ì›ë³¸ ëŒ€í™” ê¸°ë°˜ ê²€ì¦ + ì¶”ì¸¡ ì œê±°")

print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
print(f"  1. Dev ì…‹ ROUGE í‰ê°€")
print(f"  2. v4_originalê³¼ ë¹„êµ")
print(f"  3. v3_microtunedì™€ ë¹„êµ")

print(f"\n" + "="*80 + "\n")
